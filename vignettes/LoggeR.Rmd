---
title: "LoggeR - A gentle introduction"
author: "Martin Biuw"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LoggeR - A gentle introduction}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, eval=F)
```

</br>

# Reading data from a Logger Access database
Communicating with a Microsoft Access database from R or Rstudio is not straightforward. Due to lack of driver support and other issues, this cannot be done when running R/Rstudio in 64-bit mode. You will instead have to change your Rstudio session to run in 32-bit mode. Even when running R/Rstudio in 32-bit mode, there are a few steps required before you can link to a specific Access database. Most importantly, the database must first be set up as a 32-bit ODBC data source. See [here](https://support.office.com/en-us/article/administer-odbc-data-sources-b19f856b-5b9b-48c9-8b93-07484bfab5a7) for instructions.

Here we assume that the Midnatsol and Fram databases have been set up as ODBC data sources with the names `Midnatsol_20191122` and "Fram_20191202" respectively, following the instructions in the above link. You can then access them using the `readLogger` function: 

```{r readLogger}
library(LoggeR)
midnat <- readLogger()
fram <- readLogger('Fram_20191202')
```

The `Midnatsol_20191122` has been set as the default database name in the function, thus it does not need to be specified to read data from that database. Reading from any other database requires you to explicitly provide the name. 

If accessing the external database is not possible (due to complications mentioned above), then reading a version of the database stored as an RData object is simple. Assuming these RData objects are in your working directory, type:

```{r readLoggerRData}
library(LoggeR)
load('midnat.RData')
load('fram.RData')
```

Whichever method is used, you will end up with list representations of the databases, containing data frames for each table holding specific data. The `gps` data frame holds GPS position data at regular intervals (by default 1 minute), the `effort` data frame holds data on effort periods, observer rotation, weather observations etc., `sightings` holds data on whale sightings, `bsight` holds data on 10-min forward quadrant bird counts, `snapshot` holds data on snapshot bird couts behind the vessel, and `birdSpecies` holds data listing bird species codes and their respective common names.   

</br>

# Processing imported data lists
Before conducting any in-depth data analyses, the data has to be cleaned and checked. This is done in several steps. First erroneous effort start and end times are corrected using:

```{r correctEffort}
midnat <- correctEffort()
fram <- correctEffort(fram)
```

In addition to returning a modified version of the data list, where 'real' effort start and end times are given in new columns `real.start` and `real.end`, the function opens a browser window containing an interactive time chart where all events in the effort table are represented as dots. You can zoom and pan through this time chart to check that teh function has correctly determined appropriate start and end times. Note that, as when reading data from Access, all other functions uses Midnatsol data as the default. To change to Fram data this needs to be explicitly stated in the call to the functions.   

Because the USB GPS may sometimes malfunction, it may be necessary to clean up the position data in the GPS table: 

```{r filterGPS}
midnat <- filterGPS()
fram <- filterGPS(fram, maxSpeed=25)
```

The default value for `maxSpeed` is 300 knots. While this is obviously an unrealistic speed for any sea-going vessel, this proved to be the most appropriate for the Midnatsol data. This may e because of small errors in the time stamp, giving large errors in estimated speed for (accurate) positions very close in time. For the Fram dataset, this needs to be changed to a much lower value. You can experiment with different `maxSpeed`, and check the effect in the interactive map that opens up in a browser window.   

Once the GPS data has been corrected, missing positions in other data tables can be filled in by linear interpolation on time:

```{r fillGPS}
midnat <- fillGPS()
fram <- fillGPS(fram)
```

There is also an option to replace all existing positions with new interpolated ones:

```{r replaceGPS}
midnat <- fillGPS(replace.all=T)
fram <- fillGPS(fram, replace.all=T)
```

</br>

# Data display on interactive maps
Once the data have been imported and cleaned up, they can be displayed on an interactive map (similar to the map that displays when running the `filterGPS` function). The function can be run either separately for a specific data set, or for several datasets combined: 

```{r mkLeaflet}
mkLeaflet(list(midnat))
mkLeaflet(list(fram))
mkLeaflet(list(midnat, fram))
```
By default, whale data is shown, but alternatively bird data can be displayed:

```{r mkLeafletBirds}
mkLeaflet(list(midnat), birds=T)
```
</br>

# Exporting data to GIS software
To create a shapefile of all tables in a data list, you can use the function `convert2spatial`:

```{r toSpatial}
convert2spatial()
convert2spatial(fram)
```

By default, this saves shapefiles to a subdirectory of the working directory, but this can be changed if desired. Note: You will need to save data from different vessels in different directories, since they will all have the same names! This may change in a future package update.

By default, the function saves data in geographic (Lat/Lon) coordinates, but it can also be saved in UTM. This can be accomplished by specifying the relevant UTM zone and hemisphere. Fo instance, to change the data collected in the Scotia Sea to UTM format:

```{r toSpatialUTM}
convert2spatial(zone=22)
convert2spatial(fram, zone=22)
```

Options to convert to other projections may be included. However, this can also easily be accomplished in dedicated GIS packages (such as the free Qgis package and its add-ons such as Quantarctica).

Please contact the package author for assistance and requests for updates/improvements!

